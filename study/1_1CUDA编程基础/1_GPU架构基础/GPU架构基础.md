# GPU架构基础

> 理解GPU硬件架构是编写高效CUDA程序的基础

---

## 1. GPU vs CPU：设计哲学的差异

### 1.1 CPU：延迟优化（Latency-Oriented）

CPU设计的核心目标是**最小化单个任务的执行时间**：

- **少量强大的核心**：通常4-64个核心
- **大容量缓存**：L1/L2/L3缓存占据大量芯片面积
- **复杂的控制逻辑**：分支预测、乱序执行、推测执行
- **适合场景**：复杂逻辑、串行任务、低延迟响应

### 1.2 GPU：吞吐量优化（Throughput-Oriented）

GPU设计的核心目标是**最大化单位时间内完成的总工作量**：

- **大量简单的核心**：数千个CUDA核心
- **小容量缓存**：更多面积用于计算单元
- **简单的控制逻辑**：依赖大量线程隐藏延迟
- **适合场景**：大规模并行计算、数据并行任务

### 1.3 架构对比图

```
┌─────────────────────────────────────────────────────────────────┐
│                         CPU 架构                                 │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐               │
│  │  Core 0 │ │  Core 1 │ │  Core 2 │ │  Core 3 │  (少量核心)   │
│  │ ┌─────┐ │ │ ┌─────┐ │ │ ┌─────┐ │ │ ┌─────┐ │               │
│  │ │ ALU │ │ │ │ ALU │ │ │ │ ALU │ │ │ │ ALU │ │               │
│  │ └─────┘ │ │ └─────┘ │ │ └─────┘ │ │ └─────┘ │               │
│  │ ┌─────┐ │ │ ┌─────┐ │ │ ┌─────┐ │ │ ┌─────┐ │               │
│  │ │ L1  │ │ │ │ L1  │ │ │ │ L1  │ │ │ │ L1  │ │  (大缓存)    │
│  │ └─────┘ │ │ └─────┘ │ │ └─────┘ │ │ └─────┘ │               │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘               │
│  ┌─────────────────────────────────────────────┐               │
│  │              L2/L3 Cache (大)                │               │
│  └─────────────────────────────────────────────┘               │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│                         GPU 架构                                 │
├─────────────────────────────────────────────────────────────────┤
│  ┌────┐┌────┐┌────┐┌────┐┌────┐┌────┐┌────┐┌────┐              │
│  │SM 0││SM 1││SM 2││SM 3││SM 4││SM 5││SM 6││SM 7│ ...          │
│  │┌──┐││┌──┐││┌──┐││┌──┐││┌──┐││┌──┐││┌──┐││┌──┐│              │
│  ││核│││核│││核│││核│││核│││核│││核│││核││ (数千核心)        │
│  │└──┘││└──┘││└──┘││└──┘││└──┘││└──┘││└──┘││└──┘│              │
│  │┌──┐││┌──┐││┌──┐││┌──┐││┌──┐││┌──┐││┌──┐││┌──┐│              │
│  ││核│││核│││核│││核│││核│││核│││核│││核││              │
│  │└──┘││└──┘││└──┘││└──┘││└──┘││└──┘││└──┘││└──┘│              │
│  └────┘└────┘└────┘└────┘└────┘└────┘└────┘└────┘              │
│  ┌─────────────────────────────────────────────┐               │
│  │              L2 Cache (相对小)               │               │
│  └─────────────────────────────────────────────┘               │
└─────────────────────────────────────────────────────────────────┘
```

---

## 2. SIMT执行模型

### 2.1 什么是SIMT

**SIMT (Single Instruction, Multiple Threads)** 是NVIDIA GPU的执行模型：

- 多个线程执行**相同的指令**
- 但操作**不同的数据**
- 比传统SIMD更灵活：允许线程分支（但有性能代价）

### 2.2 SIMT vs SIMD

| 特性 | SIMD (CPU) | SIMT (GPU) |
|------|------------|------------|
| 执行单位 | 向量寄存器 | 线程 |
| 分支处理 | 需要掩码操作 | Warp分化（性能下降） |
| 编程模型 | 显式向量指令 | 标量代码自动并行 |
| 典型宽度 | 4-16 | 32 (Warp) |

---

## 3. SM（Streaming Multiprocessor）

### 3.1 SM是什么

SM是GPU的基本计算单元，每个SM包含：

- **CUDA核心**：执行整数和浮点运算
- **Tensor核心**：执行矩阵运算（Volta架构及以后）
- **寄存器文件**：大容量寄存器（如64K个32位寄存器）
- **共享内存/L1缓存**：可配置的片上内存
- **Warp调度器**：管理Warp的执行
- **特殊功能单元**：三角函数、超越函数等

### 3.2 SM内部结构（以Ampere架构为例）

```
┌─────────────────────────────────────────────────────────────┐
│                    Streaming Multiprocessor                  │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│   ┌─────────────────────────────────────────────────────┐   │
│   │              Warp Scheduler × 4                      │   │
│   │   (每周期可调度多个Warp的指令)                        │   │
│   └─────────────────────────────────────────────────────┘   │
│                                                              │
│   ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│   │ Processing  │  │ Processing  │  │ Processing  │        │
│   │  Block 0    │  │  Block 1    │  │  Block 2    │ ...    │
│   │             │  │             │  │             │        │
│   │ 16 FP32核心 │  │ 16 FP32核心 │  │ 16 FP32核心 │        │
│   │ 16 INT32核心│  │ 16 INT32核心│  │ 16 INT32核心│        │
│   │ 8 FP64核心  │  │ 8 FP64核心  │  │ 8 FP64核心  │        │
│   │ 1 Tensor核心│  │ 1 Tensor核心│  │ 1 Tensor核心│        │
│   └─────────────┘  └─────────────┘  └─────────────┘        │
│                                                              │
│   ┌─────────────────────────────────────────────────────┐   │
│   │             Register File (256KB)                    │   │
│   └─────────────────────────────────────────────────────┘   │
│                                                              │
│   ┌─────────────────────────────────────────────────────┐   │
│   │        Shared Memory / L1 Cache (192KB)              │   │
│   └─────────────────────────────────────────────────────┘   │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 3.3 不同架构的SM规格

| 架构 | 代表GPU | FP32核心/SM | Tensor核心/SM | 共享内存/SM |
|------|---------|-------------|---------------|-------------|
| Volta (2017) | V100 | 64 | 8 | 最大96KB |
| Turing (2018) | RTX 2080 | 64 | 8 | 最大64KB |
| Ampere (2020) | A100/RTX 3080 | 64 | 4 | 最大164KB |
| Hopper (2022) | H100 | 128 | 4 | 最大228KB |

---

## 4. Warp（线程束）

### 4.1 Warp的定义

**Warp是GPU执行的基本单位**，由32个线程组成。

关键特性：
- 同一Warp中的线程**同时执行相同指令**（SIMT）
- Warp是**硬件调度的最小单位**
- Warp内线程**隐式同步**（无需显式同步）

### 4.2 Warp调度

```
时间 →
────────────────────────────────────────────────────────────
Warp 0: │ Instr 1 │ Instr 2 │ ████████ │ Instr 3 │ Instr 4 │
        │ (执行)  │ (执行)  │ (等待内存)│ (执行)  │ (执行)  │
────────────────────────────────────────────────────────────
Warp 1: │ ████████│ Instr 1 │ Instr 2 │ ████████│ Instr 3 │
        │ (等待) │ (执行)  │ (执行)  │ (等待)  │ (执行)  │
────────────────────────────────────────────────────────────
Warp 2: │ Instr 1 │ ████████│ Instr 2 │ Instr 3 │ ████████│
        │ (执行)  │ (等待)  │ (执行)  │ (执行)  │ (等待)  │
────────────────────────────────────────────────────────────

通过多Warp交错执行，隐藏内存访问延迟！
```

### 4.3 Warp分化（Warp Divergence）

当Warp内线程执行不同分支时，会发生**Warp分化**：

```cpp
// 假设Warp包含线程 0-31
if (threadIdx.x < 16) {
    // 线程 0-15 执行这里
    doSomething();
} else {
    // 线程 16-31 执行这里
    doSomethingElse();
}
```

执行过程：
1. 线程0-15执行`doSomething()`，线程16-31**等待**
2. 线程16-31执行`doSomethingElse()`，线程0-15**等待**

**代价**：执行时间是两个分支之和，而非其一！

### 4.4 避免Warp分化

```cpp
// ❌ 糟糕：细粒度分支导致分化
if (threadIdx.x % 2 == 0) { ... }

// ✅ 较好：按Warp边界分支
if (threadIdx.x / 32 == 0) { ... }  // 整个Warp走同一分支
```

---

## 5. Thread（线程）

### 5.1 线程与硬件的映射

```
软件抽象                          硬件资源
─────────────────────────────────────────────────────
Grid                             GPU设备
  │
  ├─ Block 0  ─────────────────→ SM 0 (或任意可用SM)
  │    ├─ Warp 0 (Thread 0-31)   
  │    ├─ Warp 1 (Thread 32-63)  
  │    └─ ...
  │
  ├─ Block 1  ─────────────────→ SM 1 (或任意可用SM)
  │    ├─ Warp 0
  │    └─ ...
  │
  └─ ...
```

### 5.2 线程资源限制

每个线程消耗的资源：
- **寄存器**：每个线程最多255个寄存器
- **栈空间**：局部变量、函数调用

### 5.3 Occupancy（占用率）

Occupancy = SM上活跃Warp数 / SM支持的最大Warp数

影响Occupancy的因素：
- 每个线程使用的寄存器数
- 每个Block使用的共享内存量
- 每个Block的线程数

```
高Occupancy (好)                   低Occupancy (可能有问题)
──────────────────                 ──────────────────────
SM最大支持64 Warps                 SM最大支持64 Warps
实际运行60 Warps                   实际运行16 Warps
Occupancy = 93.75%                 Occupancy = 25%

有足够Warp隐藏延迟                  可能无法充分隐藏延迟
```

---

## 6. GPU内存带宽与延迟

### 6.1 关键性能指标

| 内存类型 | 延迟 | 带宽 | 说明 |
|----------|------|------|------|
| 寄存器 | 1 周期 | 极高 | 线程私有 |
| 共享内存 | ~20 周期 | ~10 TB/s | Block内共享 |
| L1 Cache | ~30 周期 | ~8 TB/s | SM本地 |
| L2 Cache | ~200 周期 | ~4 TB/s | 全局共享 |
| Global Memory (HBM) | ~400 周期 | ~2 TB/s | 主显存 |

### 6.2 为什么GPU需要大量线程

**延迟隐藏（Latency Hiding）**：

假设Global Memory延迟为400周期，每个Warp执行一条指令需要1周期：
- 需要约400个Warp同时就绪，才能完全隐藏内存延迟
- 这就是为什么GPU需要成千上万的线程！

---

## 7. 关键术语总结

| 术语 | 英文 | 含义 |
|------|------|------|
| SM | Streaming Multiprocessor | GPU的基本计算单元 |
| Warp | Warp | 32个线程组成的执行单位 |
| SIMT | Single Instruction, Multiple Threads | GPU的执行模型 |
| 占用率 | Occupancy | SM上活跃Warp的比例 |
| 分化 | Divergence | Warp内线程执行不同分支 |
| 延迟隐藏 | Latency Hiding | 用并行线程隐藏内存延迟 |

---

## 8. 与FlashAttention的关联

FlashAttention如何利用这些架构特性：

1. **高Occupancy**：通过控制寄存器和共享内存使用量
2. **避免Warp分化**：对齐的内存访问，统一的控制流
3. **延迟隐藏**：使用异步拷贝，在等待数据时进行计算
4. **利用Tensor Core**：使用WMMA/MMA指令加速矩阵运算

---

## 📚 延伸阅读

- [NVIDIA CUDA C++ Programming Guide - Hardware Implementation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation)
- [NVIDIA GPU架构白皮书](https://www.nvidia.com/en-us/data-center/resources/ampere-architecture-whitepaper/)

