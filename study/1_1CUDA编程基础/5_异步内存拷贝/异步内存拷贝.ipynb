{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 异步内存拷贝 - 实践篇\n",
        "\n",
        "本notebook演示CUDA Stream和异步内存拷贝的使用方法。\n",
        "\n",
        "**学习目标：**\n",
        "- 理解CUDA Stream的概念\n",
        "- 掌握异步内存拷贝的用法\n",
        "- 实现计算与数据传输的重叠\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext nvcc4jupyter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CUDA Stream基础\n",
        "\n",
        "对比同步拷贝和异步拷贝的执行时间。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void simpleKernel(float* data, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        for (int i = 0; i < 100; i++) {\n",
        "            data[idx] = sinf(data[idx]) * cosf(data[idx]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"      CUDA Stream 基础演示\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    int n = 1024 * 1024;\n",
        "    size_t size = n * sizeof(float);\n",
        "    \n",
        "    // 分配Pinned Memory（异步拷贝需要）\n",
        "    float *h_data;\n",
        "    cudaMallocHost(&h_data, size);  // Pinned Memory\n",
        "    \n",
        "    float *d_data;\n",
        "    cudaMalloc(&d_data, size);\n",
        "    \n",
        "    // 初始化\n",
        "    for (int i = 0; i < n; i++) h_data[i] = 1.0f;\n",
        "    \n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    int threadsPerBlock = 256;\n",
        "    int numBlocks = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    \n",
        "    // 同步版本\n",
        "    cudaEventRecord(start);\n",
        "    cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);\n",
        "    simpleKernel<<<numBlocks, threadsPerBlock>>>(d_data, n);\n",
        "    cudaMemcpy(h_data, d_data, size, cudaMemcpyDeviceToHost);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    \n",
        "    float time_sync;\n",
        "    cudaEventElapsedTime(&time_sync, start, stop);\n",
        "    printf(\"同步版本: %.3f ms\\n\", time_sync);\n",
        "    \n",
        "    // 异步版本（使用Stream）\n",
        "    cudaStream_t stream;\n",
        "    cudaStreamCreate(&stream);\n",
        "    \n",
        "    cudaEventRecord(start);\n",
        "    cudaMemcpyAsync(d_data, h_data, size, cudaMemcpyHostToDevice, stream);\n",
        "    simpleKernel<<<numBlocks, threadsPerBlock, 0, stream>>>(d_data, n);\n",
        "    cudaMemcpyAsync(h_data, d_data, size, cudaMemcpyDeviceToHost, stream);\n",
        "    cudaStreamSynchronize(stream);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    \n",
        "    float time_async;\n",
        "    cudaEventElapsedTime(&time_async, start, stop);\n",
        "    printf(\"异步版本: %.3f ms\\n\", time_async);\n",
        "    \n",
        "    printf(\"\\n说明: 单Stream情况下时间相近，\\n\");\n",
        "    printf(\"      异步的优势在于CPU可以同时做其他工作\\n\");\n",
        "    \n",
        "    cudaStreamDestroy(stream);\n",
        "    cudaFreeHost(h_data);\n",
        "    cudaFree(d_data);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 多Stream并行\n",
        "\n",
        "使用多个Stream实现真正的重叠执行。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void processChunk(float* data, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        for (int i = 0; i < 200; i++) {\n",
        "            data[idx] = sinf(data[idx]) * cosf(data[idx]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"        多Stream并行演示\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    const int numStreams = 4;\n",
        "    int n = 4 * 1024 * 1024;  // 4M elements\n",
        "    int chunkSize = n / numStreams;\n",
        "    size_t totalSize = n * sizeof(float);\n",
        "    size_t chunkBytes = chunkSize * sizeof(float);\n",
        "    \n",
        "    // Pinned Memory\n",
        "    float *h_data;\n",
        "    cudaMallocHost(&h_data, totalSize);\n",
        "    \n",
        "    float *d_data;\n",
        "    cudaMalloc(&d_data, totalSize);\n",
        "    \n",
        "    for (int i = 0; i < n; i++) h_data[i] = 1.0f;\n",
        "    \n",
        "    cudaStream_t streams[numStreams];\n",
        "    for (int i = 0; i < numStreams; i++) {\n",
        "        cudaStreamCreate(&streams[i]);\n",
        "    }\n",
        "    \n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerChunk = (chunkSize + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    \n",
        "    printf(\"总数据量: %d 元素\\n\", n);\n",
        "    printf(\"Stream数量: %d\\n\", numStreams);\n",
        "    printf(\"每Stream处理: %d 元素\\n\\n\", chunkSize);\n",
        "    \n",
        "    // 单Stream版本\n",
        "    cudaEventRecord(start);\n",
        "    cudaMemcpy(d_data, h_data, totalSize, cudaMemcpyHostToDevice);\n",
        "    processChunk<<<n / threadsPerBlock, threadsPerBlock>>>(d_data, n);\n",
        "    cudaMemcpy(h_data, d_data, totalSize, cudaMemcpyDeviceToHost);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    \n",
        "    float time_single;\n",
        "    cudaEventElapsedTime(&time_single, start, stop);\n",
        "    printf(\"单Stream: %.3f ms\\n\", time_single);\n",
        "    \n",
        "    // 多Stream版本\n",
        "    cudaEventRecord(start);\n",
        "    for (int i = 0; i < numStreams; i++) {\n",
        "        int offset = i * chunkSize;\n",
        "        cudaMemcpyAsync(d_data + offset, h_data + offset, chunkBytes, \n",
        "                        cudaMemcpyHostToDevice, streams[i]);\n",
        "        processChunk<<<blocksPerChunk, threadsPerBlock, 0, streams[i]>>>(\n",
        "            d_data + offset, chunkSize);\n",
        "        cudaMemcpyAsync(h_data + offset, d_data + offset, chunkBytes,\n",
        "                        cudaMemcpyDeviceToHost, streams[i]);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    \n",
        "    float time_multi;\n",
        "    cudaEventElapsedTime(&time_multi, start, stop);\n",
        "    printf(\"多Stream: %.3f ms\\n\", time_multi);\n",
        "    printf(\"加速比:   %.2fx\\n\", time_single / time_multi);\n",
        "    \n",
        "    // 清理\n",
        "    for (int i = 0; i < numStreams; i++) {\n",
        "        cudaStreamDestroy(streams[i]);\n",
        "    }\n",
        "    cudaFreeHost(h_data);\n",
        "    cudaFree(d_data);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 总结\n",
        "\n",
        "**关键要点：**\n",
        "\n",
        "1. **CUDA Stream** - 命令队列，同一Stream内顺序执行，不同Stream可并行\n",
        "2. **异步拷贝** - 使用cudaMemcpyAsync + Pinned Memory\n",
        "3. **多Stream策略** - 将工作分块分配到不同Stream，实现传输与计算重叠\n",
        "\n",
        "**练习：** 尝试不同Stream数量找最优值；实现双缓冲kernel\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
