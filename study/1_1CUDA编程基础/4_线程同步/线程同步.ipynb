{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 线程同步 - 实践篇\n",
        "\n",
        "本notebook通过实际代码演示线程同步的重要性和正确用法。\n",
        "\n",
        "**学习目标：**\n",
        "- 理解竞争条件的问题\n",
        "- 掌握 `__syncthreads()` 的正确使用\n",
        "- 学习并行规约算法\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext nvcc4jupyter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 没有同步的问题\n",
        "\n",
        "演示在共享内存中缺少同步导致的错误结果。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// 错误示例：没有同步\n",
        "__global__ void noSync(int* output) {\n",
        "    __shared__ int sdata[256];\n",
        "    \n",
        "    int tid = threadIdx.x;\n",
        "    \n",
        "    // 每个线程写入自己的位置\n",
        "    sdata[tid] = tid;\n",
        "    \n",
        "    // ❌ 没有同步！\n",
        "    // 可能读到未初始化的数据\n",
        "    \n",
        "    // 尝试读取下一个线程的值\n",
        "    int neighbor = sdata[(tid + 1) % 256];\n",
        "    \n",
        "    output[tid] = neighbor;\n",
        "}\n",
        "\n",
        "// 正确示例：使用__syncthreads()\n",
        "__global__ void withSync(int* output) {\n",
        "    __shared__ int sdata[256];\n",
        "    \n",
        "    int tid = threadIdx.x;\n",
        "    \n",
        "    // 每个线程写入自己的位置\n",
        "    sdata[tid] = tid;\n",
        "    \n",
        "    __syncthreads();  // ✓ 等待所有线程完成写入\n",
        "    \n",
        "    // 现在可以安全读取任意位置\n",
        "    int neighbor = sdata[(tid + 1) % 256];\n",
        "    \n",
        "    output[tid] = neighbor;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"      同步 vs 无同步 对比演示\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    int n = 256;\n",
        "    int *d_output, *h_output;\n",
        "    h_output = (int*)malloc(n * sizeof(int));\n",
        "    cudaMalloc(&d_output, n * sizeof(int));\n",
        "    \n",
        "    // 测试无同步版本（多次运行可能看到不同结果）\n",
        "    printf(\"无同步版本 (可能有错误):\\n\");\n",
        "    int errorCount = 0;\n",
        "    for (int run = 0; run < 10; run++) {\n",
        "        cudaMemset(d_output, 0, n * sizeof(int));\n",
        "        noSync<<<1, 256>>>(d_output);\n",
        "        cudaMemcpy(h_output, d_output, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "        \n",
        "        // 检查结果\n",
        "        int errors = 0;\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            int expected = (i + 1) % 256;\n",
        "            if (h_output[i] != expected) errors++;\n",
        "        }\n",
        "        if (errors > 0) errorCount++;\n",
        "    }\n",
        "    printf(\"  10次运行中出错次数: %d\\n\\n\", errorCount);\n",
        "    \n",
        "    // 测试有同步版本\n",
        "    printf(\"有同步版本 (总是正确):\\n\");\n",
        "    withSync<<<1, 256>>>(d_output);\n",
        "    cudaMemcpy(h_output, d_output, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    int correct = 1;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        int expected = (i + 1) % 256;\n",
        "        if (h_output[i] != expected) {\n",
        "            correct = 0;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    printf(\"  结果: %s\\n\", correct ? \"正确 ✓\" : \"错误 ✗\");\n",
        "    printf(\"  示例: output[0]=%d (期望1), output[255]=%d (期望0)\\n\", \n",
        "           h_output[0], h_output[255]);\n",
        "    \n",
        "    cudaFree(d_output);\n",
        "    free(h_output);\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 并行规约（Reduction）\n",
        "\n",
        "并行求和是同步使用的经典示例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// 并行规约求和\n",
        "__global__ void reduce(float* input, float* output, int n) {\n",
        "    __shared__ float sdata[BLOCK_SIZE];\n",
        "    \n",
        "    int tid = threadIdx.x;\n",
        "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    // 加载到共享内存\n",
        "    sdata[tid] = (gid < n) ? input[gid] : 0.0f;\n",
        "    __syncthreads();\n",
        "    \n",
        "    // 规约过程\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();  // 每一步都需要同步！\n",
        "    }\n",
        "    \n",
        "    // Block的结果\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"           并行规约求和\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    int n = 1024;\n",
        "    size_t size = n * sizeof(float);\n",
        "    \n",
        "    float *h_input = (float*)malloc(size);\n",
        "    float *h_output = (float*)malloc(size);\n",
        "    \n",
        "    // 初始化: 1+2+3+...+n = n*(n+1)/2\n",
        "    float expected = 0.0f;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_input[i] = (float)(i + 1);\n",
        "        expected += h_input[i];\n",
        "    }\n",
        "    \n",
        "    float *d_input, *d_output;\n",
        "    cudaMalloc(&d_input, size);\n",
        "    cudaMalloc(&d_output, size);\n",
        "    cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "    \n",
        "    int numBlocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    \n",
        "    printf(\"数组大小: %d\\n\", n);\n",
        "    printf(\"Block大小: %d\\n\", BLOCK_SIZE);\n",
        "    printf(\"Block数量: %d\\n\\n\", numBlocks);\n",
        "    \n",
        "    // 第一次规约\n",
        "    reduce<<<numBlocks, BLOCK_SIZE>>>(d_input, d_output, n);\n",
        "    \n",
        "    // 如果有多个Block，需要继续规约\n",
        "    while (numBlocks > 1) {\n",
        "        int newNumBlocks = (numBlocks + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "        reduce<<<newNumBlocks, BLOCK_SIZE>>>(d_output, d_output, numBlocks);\n",
        "        numBlocks = newNumBlocks;\n",
        "    }\n",
        "    \n",
        "    cudaMemcpy(h_output, d_output, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    printf(\"期望结果: %.0f\\n\", expected);\n",
        "    printf(\"GPU结果:  %.0f\\n\", h_output[0]);\n",
        "    printf(\"正确性:   %s\\n\", (h_output[0] == expected) ? \"✓ 正确\" : \"✗ 错误\");\n",
        "    \n",
        "    printf(\"\\n规约过程示意 (以8个元素为例):\\n\");\n",
        "    printf(\"Step 0: [1][2][3][4][5][6][7][8]\\n\");\n",
        "    printf(\"Step 1: [3]   [7]   [11]  [15]   (stride=4)\\n\");\n",
        "    printf(\"Step 2: [10]        [26]         (stride=2)\\n\");\n",
        "    printf(\"Step 3: [36]                     (stride=1)\\n\");\n",
        "    \n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 原子操作\n",
        "\n",
        "当多个线程需要更新同一内存位置时，使用原子操作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// 错误：竞争条件\n",
        "__global__ void incrementBad(int* counter) {\n",
        "    (*counter)++;  // 读-改-写不是原子的\n",
        "}\n",
        "\n",
        "// 正确：使用原子操作\n",
        "__global__ void incrementGood(int* counter) {\n",
        "    atomicAdd(counter, 1);  // 原子操作\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"           原子操作演示\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    int *d_counter;\n",
        "    int h_counter;\n",
        "    cudaMalloc(&d_counter, sizeof(int));\n",
        "    \n",
        "    int numThreads = 1024 * 1024;  // 100万个线程\n",
        "    int threadsPerBlock = 256;\n",
        "    int numBlocks = numThreads / threadsPerBlock;\n",
        "    \n",
        "    printf(\"线程总数: %d\\n\\n\", numThreads);\n",
        "    \n",
        "    // 测试非原子版本\n",
        "    cudaMemset(d_counter, 0, sizeof(int));\n",
        "    incrementBad<<<numBlocks, threadsPerBlock>>>(d_counter);\n",
        "    cudaMemcpy(&h_counter, d_counter, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"非原子操作结果: %d (期望: %d)\\n\", h_counter, numThreads);\n",
        "    \n",
        "    // 测试原子版本\n",
        "    cudaMemset(d_counter, 0, sizeof(int));\n",
        "    incrementGood<<<numBlocks, threadsPerBlock>>>(d_counter);\n",
        "    cudaMemcpy(&h_counter, d_counter, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"原子操作结果:   %d (期望: %d)\\n\", h_counter, numThreads);\n",
        "    \n",
        "    printf(\"\\n结论: 原子操作确保结果正确，但性能较低\\n\");\n",
        "    \n",
        "    cudaFree(d_counter);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 总结\n",
        "\n",
        "**关键要点：**\n",
        "\n",
        "1. **`__syncthreads()`**\n",
        "   - Block内所有线程必须执行\n",
        "   - 用于共享内存读写同步\n",
        "   - 不能放在条件分支中\n",
        "\n",
        "2. **同步时机**\n",
        "   - 写入共享内存后\n",
        "   - 读取其他线程写入的数据前\n",
        "   - 规约的每一步\n",
        "\n",
        "3. **原子操作**\n",
        "   - 用于多线程更新同一位置\n",
        "   - 性能较低，尽量减少使用\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 实现并行求最大值（类似规约）\n",
        "2. 使用共享内存优化的直方图计算\n",
        "3. 尝试去掉规约中的`__syncthreads()`，观察结果\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
