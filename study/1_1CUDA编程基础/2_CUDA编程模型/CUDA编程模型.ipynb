{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CUDA编程模型 - 实践篇\n",
        "\n",
        "本notebook通过实际代码帮助你理解CUDA的线程组织结构。\n",
        "\n",
        "**学习目标：**\n",
        "- 编写第一个CUDA Kernel\n",
        "- 理解Grid/Block/Thread的索引计算\n",
        "- 掌握1D/2D配置的使用方法\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext nvcc4jupyter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Hello World - 第一个CUDA Kernel\n",
        "\n",
        "每个线程打印自己的索引信息，观察线程的组织结构。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "// __global__ 标记这是一个Kernel函数，可以从CPU调用，在GPU上执行\n",
        "__global__ void helloKernel() {\n",
        "    // 计算全局线程索引\n",
        "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    printf(\"Hello from Thread %d (Block %d, Thread %d in block)\\n\",\n",
        "           globalIdx, blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"          CUDA Hello World\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    // 启动配置: 2个Block，每Block 4个线程，共8个线程\n",
        "    printf(\"启动配置: <<<2, 4>>> (2 Blocks × 4 Threads = 8 Threads)\\n\\n\");\n",
        "    \n",
        "    helloKernel<<<2, 4>>>();\n",
        "    \n",
        "    // 等待GPU完成\n",
        "    cudaDeviceSynchronize();\n",
        "    \n",
        "    printf(\"\\n注意: 线程的打印顺序可能是乱序的，因为它们是并行执行的！\\n\");\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 向量加法 - 1D线程配置\n",
        "\n",
        "这是CUDA编程的经典入门示例：两个向量相加。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// 向量加法Kernel\n",
        "__global__ void vectorAdd(float* a, float* b, float* c, int n) {\n",
        "    // 计算全局索引\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    // 边界检查：防止越界访问\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"            向量加法示例\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    int n = 1000;  // 向量长度\n",
        "    size_t size = n * sizeof(float);\n",
        "    \n",
        "    // 分配Host内存\n",
        "    float *h_a = (float*)malloc(size);\n",
        "    float *h_b = (float*)malloc(size);\n",
        "    float *h_c = (float*)malloc(size);\n",
        "    \n",
        "    // 初始化数据\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i;\n",
        "        h_b[i] = i * 2;\n",
        "    }\n",
        "    \n",
        "    // 分配Device内存\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "    \n",
        "    // 拷贝数据到GPU\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // 计算Grid和Block大小\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    \n",
        "    printf(\"向量长度: %d\\n\", n);\n",
        "    printf(\"每Block线程数: %d\\n\", threadsPerBlock);\n",
        "    printf(\"Block数量: %d\\n\", blocksPerGrid);\n",
        "    printf(\"总线程数: %d\\n\\n\", blocksPerGrid * threadsPerBlock);\n",
        "    \n",
        "    // 启动Kernel\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    \n",
        "    // 拷贝结果回Host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // 验证结果\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        if (h_c[i] != h_a[i] + h_b[i]) {\n",
        "            success = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    printf(\"验证结果: %s\\n\", success ? \"通过 ✓\" : \"失败 ✗\");\n",
        "    printf(\"示例: c[0] = a[0] + b[0] = %.0f + %.0f = %.0f\\n\", h_a[0], h_b[0], h_c[0]);\n",
        "    printf(\"示例: c[999] = a[999] + b[999] = %.0f + %.0f = %.0f\\n\", h_a[999], h_b[999], h_c[999]);\n",
        "    \n",
        "    // 清理\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 2D索引 - 矩阵元素访问\n",
        "\n",
        "对于2D数据（如图像、矩阵），使用2D线程配置更直观。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// 矩阵初始化Kernel - 每个线程处理一个元素\n",
        "__global__ void matrixInit(float* matrix, int width, int height) {\n",
        "    // 计算2D坐标\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    // 边界检查\n",
        "    if (col < width && row < height) {\n",
        "        // 计算线性索引 (行优先存储)\n",
        "        int idx = row * width + col;\n",
        "        // 将坐标值存入矩阵\n",
        "        matrix[idx] = row * 10 + col;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"          2D索引示例 - 矩阵初始化\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    int width = 8;\n",
        "    int height = 4;\n",
        "    size_t size = width * height * sizeof(float);\n",
        "    \n",
        "    float *h_matrix = (float*)malloc(size);\n",
        "    float *d_matrix;\n",
        "    cudaMalloc(&d_matrix, size);\n",
        "    \n",
        "    // 2D Block配置\n",
        "    dim3 blockDim(4, 2);  // 4×2 = 8 threads per block\n",
        "    dim3 gridDim((width + blockDim.x - 1) / blockDim.x,\n",
        "                 (height + blockDim.y - 1) / blockDim.y);\n",
        "    \n",
        "    printf(\"矩阵大小: %d × %d\\n\", width, height);\n",
        "    printf(\"Block大小: (%d, %d)\\n\", blockDim.x, blockDim.y);\n",
        "    printf(\"Grid大小: (%d, %d)\\n\\n\", gridDim.x, gridDim.y);\n",
        "    \n",
        "    matrixInit<<<gridDim, blockDim>>>(d_matrix, width, height);\n",
        "    cudaMemcpy(h_matrix, d_matrix, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    // 打印矩阵\n",
        "    printf(\"生成的矩阵 (值 = row*10 + col):\\n\");\n",
        "    for (int row = 0; row < height; row++) {\n",
        "        printf(\"  \");\n",
        "        for (int col = 0; col < width; col++) {\n",
        "            printf(\"%4.0f \", h_matrix[row * width + col]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    \n",
        "    cudaFree(d_matrix);\n",
        "    free(h_matrix);\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 理解索引计算\n",
        "\n",
        "可视化展示线程索引如何映射到数据元素。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void visualizeIndex() {\n",
        "    int globalX = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int globalY = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int globalIdx = globalY * (gridDim.x * blockDim.x) + globalX;\n",
        "    \n",
        "    printf(\"Block(%d,%d) Thread(%d,%d) -> Global(%d,%d) -> Linear %d\\n\",\n",
        "           blockIdx.x, blockIdx.y,\n",
        "           threadIdx.x, threadIdx.y,\n",
        "           globalX, globalY,\n",
        "           globalIdx);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"==========================================\\n\");\n",
        "    printf(\"          索引计算可视化\\n\");\n",
        "    printf(\"==========================================\\n\\n\");\n",
        "    \n",
        "    printf(\"配置: Grid(2,2) × Block(2,2) = 16个线程\\n\\n\");\n",
        "    \n",
        "    dim3 gridDim(2, 2);\n",
        "    dim3 blockDim(2, 2);\n",
        "    \n",
        "    visualizeIndex<<<gridDim, blockDim>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    \n",
        "    printf(\"\\n索引公式:\\n\");\n",
        "    printf(\"  globalX = blockIdx.x * blockDim.x + threadIdx.x\\n\");\n",
        "    printf(\"  globalY = blockIdx.y * blockDim.y + threadIdx.y\\n\");\n",
        "    printf(\"  linearIdx = globalY * totalWidth + globalX\\n\");\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 总结\n",
        "\n",
        "**关键概念：**\n",
        "\n",
        "1. **Kernel函数** (`__global__`)\n",
        "   - 在GPU上执行，由CPU调用\n",
        "   - 语法: `kernel<<<gridDim, blockDim>>>(args)`\n",
        "\n",
        "2. **线程索引**\n",
        "   - `threadIdx`: 线程在Block内的索引\n",
        "   - `blockIdx`: Block在Grid内的索引\n",
        "   - `blockDim`/`gridDim`: Block/Grid的维度\n",
        "\n",
        "3. **全局索引计算**\n",
        "   - 1D: `idx = blockIdx.x * blockDim.x + threadIdx.x`\n",
        "   - 2D: `row/col = blockIdx.y/x * blockDim.y/x + threadIdx.y/x`\n",
        "\n",
        "4. **常用Block大小**\n",
        "   - 1D: 128, 256, 512\n",
        "   - 2D: (16,16), (32,8), (8,32)\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 修改向量加法，尝试不同的Block大小，观察是否有性能差异\n",
        "2. 实现矩阵加法（两个矩阵相加）\n",
        "3. 实现一个kernel，将矩阵每个元素乘以其行号\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
