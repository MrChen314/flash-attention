{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TiledCopy内存拷贝 - 实践篇\n",
        "\n",
        "本notebook帮助你理解cute的TiledCopy抽象及其在FlashAttention中的应用。\n",
        "\n",
        "**学习目标：**\n",
        "- 理解GPU内存层次和数据传输\n",
        "- 理解TiledCopy的组成和使用\n",
        "- 分析异步拷贝流水线的原理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. GPU内存层次可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_memory_hierarchy():\n",
        "    \"\"\"可视化GPU内存层次\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.set_xlim(0, 10)\n",
        "    ax.set_ylim(0, 10)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    # 寄存器\n",
        "    rect1 = plt.Rectangle((2, 7), 6, 1.5, fill=True, \n",
        "                           facecolor='lightcoral', edgecolor='darkred', linewidth=2)\n",
        "    ax.add_patch(rect1)\n",
        "    ax.text(5, 7.75, '寄存器 (Registers)\\n最快 | 每线程私有 | MMA输入输出', \n",
        "            ha='center', va='center', fontsize=10)\n",
        "    \n",
        "    # 共享内存\n",
        "    rect2 = plt.Rectangle((2, 4.5), 6, 1.5, fill=True, \n",
        "                           facecolor='lightyellow', edgecolor='orange', linewidth=2)\n",
        "    ax.add_patch(rect2)\n",
        "    ax.text(5, 5.25, '共享内存 (SMEM)\\n~20周期延迟 | 线程块共享 | 数据暂存', \n",
        "            ha='center', va='center', fontsize=10)\n",
        "    \n",
        "    # 全局内存\n",
        "    rect3 = plt.Rectangle((2, 2), 6, 1.5, fill=True, \n",
        "                           facecolor='lightblue', edgecolor='darkblue', linewidth=2)\n",
        "    ax.add_patch(rect3)\n",
        "    ax.text(5, 2.75, '全局内存 (HBM)\\n~400周期延迟 | 所有线程 | 输入输出数据', \n",
        "            ha='center', va='center', fontsize=10)\n",
        "    \n",
        "    # 箭头和标签\n",
        "    ax.annotate('', xy=(5, 7), xytext=(5, 6.2),\n",
        "                arrowprops=dict(arrowstyle='<->', color='green', lw=2))\n",
        "    ax.text(7, 6.6, 'S2R / R2S\\n(ldmatrix)', ha='left', fontsize=9, color='green')\n",
        "    \n",
        "    ax.annotate('', xy=(5, 4.5), xytext=(5, 3.7),\n",
        "                arrowprops=dict(arrowstyle='<->', color='blue', lw=2))\n",
        "    ax.text(7, 4.1, 'G2S / S2G\\n(cp.async)', ha='left', fontsize=9, color='blue')\n",
        "    \n",
        "    # 性能数据\n",
        "    ax.text(0.5, 0.8, 'A100 性能: HBM带宽 2TB/s, SMEM带宽 ~19TB/s', fontsize=10)\n",
        "    ax.text(0.5, 0.4, 'TiledCopy的作用: 封装这些传输操作，优化带宽利用', fontsize=10, style='italic')\n",
        "    \n",
        "    ax.set_title('GPU内存层次与TiledCopy', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_memory_hierarchy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. TiledCopy的线程分配\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_thread_layout():\n",
        "    \"\"\"可视化TiledCopy的线程分配\"\"\"\n",
        "    # 假设 ThreadLayout = (16, 8), ValueLayout = (1, 8)\n",
        "    # 每个线程处理 1×8 = 8 个元素\n",
        "    # 总tile: 16×64\n",
        "    \n",
        "    thread_layout = (16, 8)  # 16行8列的线程\n",
        "    value_layout = (1, 8)    # 每线程1行8列\n",
        "    \n",
        "    tile_m = thread_layout[0] * value_layout[0]  # 16\n",
        "    tile_n = thread_layout[1] * value_layout[1]  # 64\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # 左图: 线程布局\n",
        "    ax = axes[0]\n",
        "    thread_grid = np.arange(thread_layout[0] * thread_layout[1]).reshape(thread_layout)\n",
        "    im = ax.imshow(thread_grid, cmap='tab20', vmin=0, vmax=127)\n",
        "    ax.set_title(f'ThreadLayout: {thread_layout[0]}×{thread_layout[1]}=128线程')\n",
        "    ax.set_xlabel('线程列')\n",
        "    ax.set_ylabel('线程行')\n",
        "    \n",
        "    for i in range(thread_layout[0]):\n",
        "        for j in range(thread_layout[1]):\n",
        "            ax.text(j, i, f'T{thread_grid[i,j]}', ha='center', va='center', \n",
        "                   fontsize=6, color='white')\n",
        "    \n",
        "    plt.colorbar(im, ax=ax, label='线程ID')\n",
        "    \n",
        "    # 右图: 数据分配\n",
        "    ax = axes[1]\n",
        "    data_assign = np.zeros((tile_m, tile_n), dtype=int)\n",
        "    for ti in range(thread_layout[0]):\n",
        "        for tj in range(thread_layout[1]):\n",
        "            thread_id = ti * thread_layout[1] + tj\n",
        "            for vi in range(value_layout[0]):\n",
        "                for vj in range(value_layout[1]):\n",
        "                    di = ti * value_layout[0] + vi\n",
        "                    dj = tj * value_layout[1] + vj\n",
        "                    data_assign[di, dj] = thread_id\n",
        "    \n",
        "    im = ax.imshow(data_assign, cmap='tab20', vmin=0, vmax=127)\n",
        "    ax.set_title(f'数据Tile: {tile_m}×{tile_n}\\\\n每个颜色=一个线程负责的区域')\n",
        "    ax.set_xlabel('列')\n",
        "    ax.set_ylabel('行')\n",
        "    plt.colorbar(im, ax=ax, label='负责的线程ID')\n",
        "    \n",
        "    plt.suptitle('TiledCopy线程到数据的映射', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"ThreadLayout: {thread_layout} = {thread_layout[0]*thread_layout[1]} 线程\")\n",
        "    print(f\"ValueLayout: {value_layout} = 每线程 {value_layout[0]*value_layout[1]} 元素\")\n",
        "    print(f\"总Tile大小: {tile_m}×{tile_n} = {tile_m*tile_n} 元素\")\n",
        "    print(f\"每线程处理: {tile_m*tile_n//(thread_layout[0]*thread_layout[1])} 元素\")\n",
        "\n",
        "visualize_thread_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 异步拷贝流水线\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_pipeline():\n",
        "    \"\"\"可视化异步拷贝流水线\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    \n",
        "    # 时间轴\n",
        "    num_iters = 6\n",
        "    stages = 2\n",
        "    \n",
        "    y_positions = {'Load Stage 0': 3, 'Load Stage 1': 2, 'Compute': 1}\n",
        "    colors = {'Load Stage 0': 'lightblue', 'Load Stage 1': 'lightgreen', 'Compute': 'lightyellow'}\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "        stage = i % stages\n",
        "        \n",
        "        # 加载操作\n",
        "        load_y = y_positions[f'Load Stage {stage}']\n",
        "        load_rect = plt.Rectangle((i*1.5, load_y - 0.3), 1.2, 0.6, \n",
        "                                   facecolor=colors[f'Load Stage {stage}'], \n",
        "                                   edgecolor='black')\n",
        "        ax.add_patch(load_rect)\n",
        "        ax.text(i*1.5 + 0.6, load_y, f'Load K{i}', ha='center', va='center', fontsize=9)\n",
        "        \n",
        "        # 计算操作 (延迟一个迭代)\n",
        "        if i > 0:\n",
        "            compute_rect = plt.Rectangle((i*1.5, y_positions['Compute'] - 0.3), 1.2, 0.6, \n",
        "                                         facecolor=colors['Compute'], \n",
        "                                         edgecolor='black')\n",
        "            ax.add_patch(compute_rect)\n",
        "            ax.text(i*1.5 + 0.6, y_positions['Compute'], f'MMA K{i-1}', \n",
        "                   ha='center', va='center', fontsize=9)\n",
        "    \n",
        "    # 标签\n",
        "    ax.text(-0.5, 3, 'Stage 0', ha='right', va='center', fontsize=10)\n",
        "    ax.text(-0.5, 2, 'Stage 1', ha='right', va='center', fontsize=10)\n",
        "    ax.text(-0.5, 1, '计算', ha='right', va='center', fontsize=10)\n",
        "    \n",
        "    ax.set_xlim(-1, num_iters * 1.5 + 0.5)\n",
        "    ax.set_ylim(0, 4)\n",
        "    ax.set_xlabel('时间 →', fontsize=12)\n",
        "    ax.set_title('双缓冲异步拷贝流水线\\\\n加载和计算重叠，隐藏内存延迟', fontsize=14)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"流水线关键点:\")\n",
        "    print(\"1. cp.async 发起异步拷贝，不等待完成\")\n",
        "    print(\"2. cp_async_fence() 标记一组拷贝\")\n",
        "    print(\"3. cp_async_wait<N>() 等待直到只剩N组未完成\")\n",
        "    print(\"4. 双缓冲: 一边加载下一块，一边计算当前块\")\n",
        "\n",
        "visualize_pipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. FlashAttention中的TiledCopy代码分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tiledcopy_code = '''\n",
        "// ============================================================\n",
        "// FlashAttention中的TiledCopy使用模式\n",
        "// 来自 hopper/mainloop_fwd_sm80.hpp\n",
        "// ============================================================\n",
        "\n",
        "// 1. 定义G2S TiledCopy (全局内存 → 共享内存)\n",
        "using GmemTiledCopyQKV = TiledCopy<\n",
        "    Copy_Atom<SM80_CP_ASYNC_CACHEGLOBAL<cute::uint128_t>, Element>,\n",
        "    Layout<Shape<_16, _8>>,    // 16×8 线程布局\n",
        "    Layout<Shape<_1, _8>>      // 每线程处理 1×8\n",
        ">;\n",
        "\n",
        "// 2. 创建TiledCopy并获取线程视图\n",
        "GmemTiledCopyQKV gmem_tiled_copy_QKV;\n",
        "auto gmem_thr_copy_QKV = gmem_tiled_copy_QKV.get_thread_slice(threadIdx.x);\n",
        "\n",
        "// 3. 分区源和目标Tensor\n",
        "Tensor tQgQ = gmem_thr_copy_QKV.partition_S(gQ);  // 全局内存Q\n",
        "Tensor tQsQ = gmem_thr_copy_QKV.partition_D(sQ);  // 共享内存Q\n",
        "\n",
        "// 4. 执行异步拷贝\n",
        "cute::copy(gmem_tiled_copy_QKV, tQgQ, tQsQ);\n",
        "cute::cp_async_fence();\n",
        "\n",
        "// 5. 等待拷贝完成\n",
        "cute::cp_async_wait<0>();\n",
        "__syncthreads();\n",
        "\n",
        "// ============================================================\n",
        "// S2R拷贝 (共享内存 → 寄存器，为MMA准备)\n",
        "// ============================================================\n",
        "\n",
        "// 创建与MMA配合的SMEM拷贝\n",
        "auto smem_tiled_copy_A = make_tiled_copy_A(SmemCopyAtom{}, tiled_mma);\n",
        "auto smem_thr_copy_A = smem_tiled_copy_A.get_thread_slice(threadIdx.x);\n",
        "\n",
        "// 分区\n",
        "Tensor tCsQ = smem_thr_copy_A.partition_S(sQ);\n",
        "Tensor tCrQ = smem_thr_copy_A.retile_D(tCrQ_mma);  // retile匹配MMA布局\n",
        "\n",
        "// 拷贝到寄存器\n",
        "cute::copy(smem_tiled_copy_A, tCsQ(_, _, k), tCrQ(_, _, k));\n",
        "'''\n",
        "\n",
        "print(tiledcopy_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 数据流模拟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_data_flow():\n",
        "    \"\"\"模拟FlashAttention的数据流\"\"\"\n",
        "    print(\"FlashAttention 数据流\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 配置\n",
        "    seqlen = 2048\n",
        "    headdim = 64\n",
        "    kBlockM = 128\n",
        "    kBlockN = 64\n",
        "    \n",
        "    num_q_blocks = seqlen // kBlockM\n",
        "    num_kv_blocks = seqlen // kBlockN\n",
        "    \n",
        "    print(f\"配置: seqlen={seqlen}, headdim={headdim}\")\n",
        "    print(f\"      kBlockM={kBlockM}, kBlockN={kBlockN}\")\n",
        "    print()\n",
        "    \n",
        "    # 模拟一个block的数据流\n",
        "    print(\"单个Thread Block的数据流:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    print(\"\"\"\n",
        "1. 加载Q块 (一次性)\n",
        "   GMEM → SMEM: TiledCopy(gmem_tiled_copy_Q)\n",
        "   ┌──────────────────────────────┐\n",
        "   │  Q[m_block*kBlockM : (m_block+1)*kBlockM, :headdim]  │\n",
        "   │  大小: 128×64 = 8192 元素 = 16KB (FP16)              │\n",
        "   └──────────────────────────────┘\n",
        "\n",
        "2. 循环处理K/V块\n",
        "   for n_block in range(num_kv_blocks):\n",
        "   \n",
        "       a. 加载K块\n",
        "          GMEM → SMEM: TiledCopy(gmem_tiled_copy_KV)\n",
        "          ┌──────────────────────────────┐\n",
        "          │  K[n_block*kBlockN : (n_block+1)*kBlockN, :]  │\n",
        "          │  大小: 64×64 = 4096 元素 = 8KB (FP16)         │\n",
        "          └──────────────────────────────┘\n",
        "          \n",
        "       b. 加载V块 (类似K)\n",
        "       \n",
        "       c. 同步等待拷贝完成\n",
        "          cp_async_wait<0>()\n",
        "          __syncthreads()\n",
        "       \n",
        "       d. S2R拷贝: SMEM → Register\n",
        "          TiledCopy(smem_tiled_copy)\n",
        "          \n",
        "       e. MMA计算: S = Q @ K^T\n",
        "          TiledMMA执行\n",
        "          \n",
        "       f. Softmax计算 (在寄存器中)\n",
        "       \n",
        "       g. MMA计算: O += P @ V\n",
        "\n",
        "3. 写回输出\n",
        "   Register → SMEM → GMEM\n",
        "\"\"\")\n",
        "\n",
        "simulate_data_flow()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 总结\n",
        "\n",
        "通过本notebook，你应该理解了：\n",
        "\n",
        "1. **GPU内存层次**: GMEM → SMEM → Register 的数据路径\n",
        "2. **TiledCopy组成**: Copy Atom + ThreadLayout + ValueLayout\n",
        "3. **异步拷贝**: cp.async 指令，支持流水线执行\n",
        "4. **partition操作**: 将Tensor分配给线程\n",
        "5. **FlashAttention应用**: G2S加载Q/K/V，S2R准备MMA输入\n",
        "\n",
        "## 关键代码模式\n",
        "\n",
        "```cpp\n",
        "// G2S: 全局内存 → 共享内存\n",
        "auto thr_copy = gmem_tiled_copy.get_thread_slice(threadIdx.x);\n",
        "Tensor tSgS = thr_copy.partition_S(gS);  // 源\n",
        "Tensor tSsS = thr_copy.partition_D(sS);  // 目标\n",
        "cute::copy(gmem_tiled_copy, tSgS, tSsS);\n",
        "cute::cp_async_fence();\n",
        "cute::cp_async_wait<0>();\n",
        "\n",
        "// S2R: 共享内存 → 寄存器\n",
        "auto smem_thr = smem_tiled_copy.get_thread_slice(threadIdx.x);\n",
        "Tensor tCsS = smem_thr.partition_S(sS);\n",
        "Tensor tCrS = smem_thr.retile_D(tCrS_mma);\n",
        "cute::copy(smem_tiled_copy, tCsS, tCrS);\n",
        "```\n",
        "\n",
        "## 下一步\n",
        "\n",
        "在下一节\"local_tile局部分块\"中，我们将学习如何从大Tensor中获取分块视图。\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
