{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# cuteå¼ é‡æŠ½è±¡å±‚ - å®è·µ\n",
        "\n",
        "> ç”¨Pythonæ¨¡æ‹Ÿç†è§£cuteçš„æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "---\n",
        "\n",
        "æœ¬notebooké€šè¿‡Pythonä»£ç æ¨¡æ‹Ÿcuteçš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¸®åŠ©ä½ ç†è§£ï¼š\n",
        "1. Layoutï¼ˆå¸ƒå±€ï¼‰çš„æ¦‚å¿µ\n",
        "2. Shapeå’ŒStrideå¦‚ä½•å·¥ä½œ\n",
        "3. åˆ†å—ï¼ˆTilingï¼‰æ“ä½œ\n",
        "4. ä¸ºä»€ä¹ˆè¿™äº›æŠ½è±¡å¯¹FlashAttentionå¾ˆé‡è¦\n",
        "\n",
        "**æ³¨æ„**ï¼šcuteæ˜¯C++æ¨¡æ¿åº“ï¼Œè¿™é‡Œç”¨Pythonæ¨¡æ‹Ÿå…¶æ¦‚å¿µï¼Œä¾¿äºç†è§£ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒå‡†å¤‡\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Tuple, List\n",
        "\n",
        "print(\"numpyç‰ˆæœ¬:\", np.__version__)\n",
        "print(\"\\næœ¬notebookæ¨¡æ‹Ÿcuteçš„æ¦‚å¿µï¼Œä¸éœ€è¦GPUã€‚\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ç†è§£Layout\n",
        "\n",
        "Layoutæ˜¯cuteä¸­æœ€æ ¸å¿ƒçš„æ¦‚å¿µã€‚å®ƒç”±Shapeå’ŒStrideç»„æˆï¼Œæè¿°äº†å¤šç»´æ•°æ®å¦‚ä½•æ˜ å°„åˆ°ä¸€ç»´å†…å­˜ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Layout:\n",
        "    \"\"\"\n",
        "    æ¨¡æ‹Ÿcuteçš„Layoutæ¦‚å¿µ\n",
        "    \n",
        "    Layout = (Shape, Stride)\n",
        "    - Shape: æ¯ä¸ªç»´åº¦çš„å¤§å°\n",
        "    - Stride: æ¯ä¸ªç»´åº¦ç§»åŠ¨ä¸€æ­¥åœ¨çº¿æ€§å†…å­˜ä¸­çš„åç§»\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, shape: Tuple[int, ...], stride: Tuple[int, ...] = None):\n",
        "        self.shape = shape\n",
        "        # å¦‚æœæ²¡æœ‰æä¾›strideï¼Œé»˜è®¤ä¸ºè¡Œä¼˜å…ˆï¼ˆCé¡ºåºï¼‰\n",
        "        if stride is None:\n",
        "            stride = self._compute_row_major_stride(shape)\n",
        "        self.stride = stride\n",
        "        \n",
        "    def _compute_row_major_stride(self, shape: Tuple[int, ...]) -> Tuple[int, ...]:\n",
        "        \"\"\"è®¡ç®—è¡Œä¼˜å…ˆçš„stride\"\"\"\n",
        "        stride = []\n",
        "        s = 1\n",
        "        for dim in reversed(shape):\n",
        "            stride.append(s)\n",
        "            s *= dim\n",
        "        return tuple(reversed(stride))\n",
        "    \n",
        "    def __call__(self, *indices) -> int:\n",
        "        \"\"\"è®¡ç®—çº¿æ€§ç´¢å¼•\"\"\"\n",
        "        assert len(indices) == len(self.shape)\n",
        "        offset = 0\n",
        "        for idx, s in zip(indices, self.stride):\n",
        "            offset += idx * s\n",
        "        return offset\n",
        "    \n",
        "    def size(self) -> int:\n",
        "        \"\"\"æ€»å…ƒç´ æ•°\"\"\"\n",
        "        result = 1\n",
        "        for s in self.shape:\n",
        "            result *= s\n",
        "        return result\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f\"Layout(shape={self.shape}, stride={self.stride})\"\n",
        "\n",
        "# æµ‹è¯•Layout\n",
        "print(\"=\"*60)\n",
        "print(\"Layoutç¤ºä¾‹\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# è¡Œä¼˜å…ˆçš„4x3çŸ©é˜µ\n",
        "row_major = Layout((4, 3), (3, 1))\n",
        "print(f\"\\nè¡Œä¼˜å…ˆ 4x3 çŸ©é˜µ: {row_major}\")\n",
        "print(\"ç´¢å¼• (0,0) -> çº¿æ€§åç§»:\", row_major(0, 0))\n",
        "print(\"ç´¢å¼• (0,2) -> çº¿æ€§åç§»:\", row_major(0, 2))\n",
        "print(\"ç´¢å¼• (1,0) -> çº¿æ€§åç§»:\", row_major(1, 0))\n",
        "print(\"ç´¢å¼• (2,1) -> çº¿æ€§åç§»:\", row_major(2, 1))\n",
        "\n",
        "# åˆ—ä¼˜å…ˆçš„4x3çŸ©é˜µ\n",
        "col_major = Layout((4, 3), (1, 4))\n",
        "print(f\"\\nåˆ—ä¼˜å…ˆ 4x3 çŸ©é˜µ: {col_major}\")\n",
        "print(\"ç´¢å¼• (0,0) -> çº¿æ€§åç§»:\", col_major(0, 0))\n",
        "print(\"ç´¢å¼• (0,2) -> çº¿æ€§åç§»:\", col_major(0, 2))\n",
        "print(\"ç´¢å¼• (1,0) -> çº¿æ€§åç§»:\", col_major(1, 0))\n",
        "print(\"ç´¢å¼• (2,1) -> çº¿æ€§åç§»:\", col_major(2, 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. å¯è§†åŒ–è¡Œä¼˜å…ˆ vs åˆ—ä¼˜å…ˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_layout(layout: Layout, name: str):\n",
        "    \"\"\"å¯è§†åŒ–Layoutçš„å†…å­˜æ˜ å°„\"\"\"\n",
        "    rows, cols = layout.shape\n",
        "    \n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"Shape: {layout.shape}, Stride: {layout.stride}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # é€»è¾‘è§†å›¾\n",
        "    print(\"\\né€»è¾‘è§†å›¾ (i, j):\")\n",
        "    for i in range(rows):\n",
        "        row_str = \"  \"\n",
        "        for j in range(cols):\n",
        "            row_str += f\"({i},{j})  \"\n",
        "        print(row_str)\n",
        "    \n",
        "    # çº¿æ€§å†…å­˜åç§»\n",
        "    print(\"\\nçº¿æ€§å†…å­˜åç§»:\")\n",
        "    for i in range(rows):\n",
        "        row_str = \"  \"\n",
        "        for j in range(cols):\n",
        "            offset = layout(i, j)\n",
        "            row_str += f\"[{offset:2d}]   \"\n",
        "        print(row_str)\n",
        "    \n",
        "    # å†…å­˜ä¸­çš„é¡ºåº\n",
        "    max_offset = max(layout(i, j) for i in range(rows) for j in range(cols))\n",
        "    print(f\"\\nå†…å­˜å¸ƒå±€ (0 åˆ° {max_offset}):\")\n",
        "    memory = ['--'] * (max_offset + 1)\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            offset = layout(i, j)\n",
        "            memory[offset] = f\"({i},{j})\"\n",
        "    print(\"  \" + \" \".join(memory))\n",
        "\n",
        "# å¯è§†åŒ–\n",
        "visualize_layout(Layout((3, 4), (4, 1)), \"è¡Œä¼˜å…ˆ 3x4\")\n",
        "visualize_layout(Layout((3, 4), (1, 3)), \"åˆ—ä¼˜å…ˆ 3x4\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. æ¨¡æ‹Ÿcuteçš„Tensor\n",
        "\n",
        "Tensor = æ•°æ®æŒ‡é’ˆ + Layout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Tensor:\n",
        "    \"\"\"\n",
        "    æ¨¡æ‹Ÿcuteçš„Tensoræ¦‚å¿µ\n",
        "    \n",
        "    Tensor = Data + Layout\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data: np.ndarray, layout: Layout = None):\n",
        "        self.data = data.flatten()  # æ¨¡æ‹Ÿçº¿æ€§å†…å­˜\n",
        "        if layout is None:\n",
        "            layout = Layout(data.shape)\n",
        "        self.layout = layout\n",
        "        \n",
        "    def __getitem__(self, indices):\n",
        "        if not isinstance(indices, tuple):\n",
        "            indices = (indices,)\n",
        "        offset = self.layout(*indices)\n",
        "        return self.data[offset]\n",
        "    \n",
        "    def __setitem__(self, indices, value):\n",
        "        if not isinstance(indices, tuple):\n",
        "            indices = (indices,)\n",
        "        offset = self.layout(*indices)\n",
        "        self.data[offset] = value\n",
        "    \n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.layout.shape\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f\"Tensor(shape={self.shape}, layout={self.layout})\"\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªTensor\n",
        "print(\"=\"*60)\n",
        "print(\"Tensorç¤ºä¾‹\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# åˆ›å»º3x4çŸ©é˜µ\n",
        "data = np.arange(12).reshape(3, 4).astype(np.float32)\n",
        "print(\"åŸå§‹numpyæ•°ç»„:\")\n",
        "print(data)\n",
        "\n",
        "# åŒ…è£…æˆcuteé£æ ¼çš„Tensor\n",
        "tensor = Tensor(data, Layout((3, 4), (4, 1)))  # è¡Œä¼˜å…ˆ\n",
        "print(f\"\\n{tensor}\")\n",
        "print(f\"tensor[0, 0] = {tensor[0, 0]}\")\n",
        "print(f\"tensor[1, 2] = {tensor[1, 2]}\")\n",
        "print(f\"tensor[2, 3] = {tensor[2, 3]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. local_tileï¼šè·å–å±€éƒ¨Tile\n",
        "\n",
        "è¿™æ˜¯FlashAttentionä¸­çš„æ ¸å¿ƒæ“ä½œ - ä»å¤§çŸ©é˜µä¸­è·å–ä¸€ä¸ªå°å—ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def local_tile(tensor: Tensor, tile_shape: Tuple[int, int], tile_coord: Tuple[int, int]) -> Tensor:\n",
        "    \"\"\"\n",
        "    æ¨¡æ‹Ÿcuteçš„local_tileæ“ä½œ\n",
        "    \n",
        "    ä»å¤§Tensorä¸­è·å–ä¸€ä¸ªtileçš„è§†å›¾\n",
        "    \n",
        "    å‚æ•°:\n",
        "        tensor: åŸå§‹Tensor\n",
        "        tile_shape: tileçš„å½¢çŠ¶ (tile_rows, tile_cols)\n",
        "        tile_coord: tileçš„åæ ‡ (tile_row_idx, tile_col_idx)\n",
        "    \n",
        "    è¿”å›:\n",
        "        æŒ‡å‘åŸå§‹æ•°æ®çš„Tensorè§†å›¾\n",
        "    \"\"\"\n",
        "    tile_rows, tile_cols = tile_shape\n",
        "    tile_row_idx, tile_col_idx = tile_coord\n",
        "    \n",
        "    # è®¡ç®—tileçš„èµ·å§‹ä½ç½®\n",
        "    start_row = tile_row_idx * tile_rows\n",
        "    start_col = tile_col_idx * tile_cols\n",
        "    \n",
        "    # è®¡ç®—èµ·å§‹åç§»\n",
        "    start_offset = tensor.layout(start_row, start_col)\n",
        "    \n",
        "    # åˆ›å»ºæ–°çš„Layoutï¼ˆstrideä¿æŒä¸å˜ï¼‰\n",
        "    new_layout = Layout(tile_shape, tensor.layout.stride)\n",
        "    \n",
        "    # åˆ›å»ºæ–°çš„Tensorè§†å›¾ï¼ˆå…±äº«åº•å±‚æ•°æ®ï¼Œåç§»èµ·å§‹ä½ç½®ï¼‰\n",
        "    class TensorView:\n",
        "        def __init__(self, data, offset, layout):\n",
        "            self.data = data\n",
        "            self.offset = offset\n",
        "            self.layout = layout\n",
        "            \n",
        "        def __getitem__(self, indices):\n",
        "            if not isinstance(indices, tuple):\n",
        "                indices = (indices,)\n",
        "            local_offset = self.layout(*indices)\n",
        "            return self.data[self.offset + local_offset]\n",
        "        \n",
        "        @property\n",
        "        def shape(self):\n",
        "            return self.layout.shape\n",
        "        \n",
        "        def __repr__(self):\n",
        "            return f\"TensorView(shape={self.shape}, offset={self.offset})\"\n",
        "    \n",
        "    return TensorView(tensor.data, start_offset, new_layout)\n",
        "\n",
        "# æ¼”ç¤ºlocal_tile\n",
        "print(\"=\"*60)\n",
        "print(\"local_tileæ¼”ç¤º\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# åˆ›å»º8x8çŸ©é˜µ\n",
        "big_data = np.arange(64).reshape(8, 8).astype(np.float32)\n",
        "big_tensor = Tensor(big_data, Layout((8, 8), (8, 1)))\n",
        "\n",
        "print(\"åŸå§‹8x8çŸ©é˜µ:\")\n",
        "print(big_data)\n",
        "\n",
        "# è·å–ä¸åŒä½ç½®çš„4x4 tile\n",
        "print(\"\\nè·å–4x4çš„tiles:\")\n",
        "for row_idx in range(2):\n",
        "    for col_idx in range(2):\n",
        "        tile = local_tile(big_tensor, (4, 4), (row_idx, col_idx))\n",
        "        print(f\"\\nTile[{row_idx}, {col_idx}]: {tile}\")\n",
        "        # æ‰“å°tileå†…å®¹\n",
        "        for i in range(4):\n",
        "            row = [f\"{tile[i, j]:4.0f}\" for j in range(4)]\n",
        "            print(\"  \" + \" \".join(row))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æ¨¡æ‹Ÿçº¿ç¨‹åˆ†åŒºï¼ˆPartitionï¼‰\n",
        "\n",
        "åœ¨GPUä¸Šï¼Œå¤šä¸ªçº¿ç¨‹åä½œå¤„ç†ä¸€ä¸ªtileã€‚Partitionæè¿°äº†æ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„æ•°æ®ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def partition_for_threads(tensor_shape: Tuple[int, int], \n",
        "                          num_threads: int,\n",
        "                          thread_layout: Tuple[int, int]) -> dict:\n",
        "    \"\"\"\n",
        "    æ¨¡æ‹Ÿcuteçš„partitionæ“ä½œ\n",
        "    \n",
        "    å°†tensoråˆ†é…ç»™å¤šä¸ªçº¿ç¨‹\n",
        "    \n",
        "    å‚æ•°:\n",
        "        tensor_shape: tensorçš„å½¢çŠ¶\n",
        "        num_threads: çº¿ç¨‹æ•°\n",
        "        thread_layout: çº¿ç¨‹æ’åˆ—æ–¹å¼ (thread_rows, thread_cols)\n",
        "    \n",
        "    è¿”å›:\n",
        "        æ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„å…ƒç´ ç´¢å¼•\n",
        "    \"\"\"\n",
        "    rows, cols = tensor_shape\n",
        "    thread_rows, thread_cols = thread_layout\n",
        "    \n",
        "    assert thread_rows * thread_cols == num_threads\n",
        "    \n",
        "    # æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„å…ƒç´ æ•°\n",
        "    elements_per_thread_row = rows // thread_rows\n",
        "    elements_per_thread_col = cols // thread_cols\n",
        "    \n",
        "    partitions = {}\n",
        "    \n",
        "    for thread_id in range(num_threads):\n",
        "        # è®¡ç®—çº¿ç¨‹åœ¨ç½‘æ ¼ä¸­çš„ä½ç½®\n",
        "        thread_row = thread_id // thread_cols\n",
        "        thread_col = thread_id % thread_cols\n",
        "        \n",
        "        # è®¡ç®—è¯¥çº¿ç¨‹è´Ÿè´£çš„å…ƒç´ èŒƒå›´\n",
        "        start_row = thread_row * elements_per_thread_row\n",
        "        end_row = start_row + elements_per_thread_row\n",
        "        start_col = thread_col * elements_per_thread_col\n",
        "        end_col = start_col + elements_per_thread_col\n",
        "        \n",
        "        elements = []\n",
        "        for i in range(start_row, end_row):\n",
        "            for j in range(start_col, end_col):\n",
        "                elements.append((i, j))\n",
        "        \n",
        "        partitions[thread_id] = {\n",
        "            'thread_pos': (thread_row, thread_col),\n",
        "            'range': ((start_row, end_row), (start_col, end_col)),\n",
        "            'elements': elements\n",
        "        }\n",
        "    \n",
        "    return partitions\n",
        "\n",
        "# æ¼”ç¤ºpartition\n",
        "print(\"=\"*60)\n",
        "print(\"çº¿ç¨‹åˆ†åŒºæ¼”ç¤º\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nåœºæ™¯: 8x8 çŸ©é˜µï¼Œ4ä¸ªçº¿ç¨‹ (2x2æ’åˆ—)\")\n",
        "partitions = partition_for_threads((8, 8), 4, (2, 2))\n",
        "\n",
        "for thread_id, info in partitions.items():\n",
        "    print(f\"\\nThread {thread_id}:\")\n",
        "    print(f\"  ä½ç½®: {info['thread_pos']}\")\n",
        "    print(f\"  è¡ŒèŒƒå›´: {info['range'][0]}\")\n",
        "    print(f\"  åˆ—èŒƒå›´: {info['range'][1]}\")\n",
        "    print(f\"  å…ƒç´ æ•°: {len(info['elements'])}\")\n",
        "\n",
        "# å¯è§†åŒ–åˆ†åŒº\n",
        "print(\"\\nåˆ†åŒºå¯è§†åŒ– (æ•°å­—è¡¨ç¤ºthread_id):\")\n",
        "grid = np.zeros((8, 8), dtype=int)\n",
        "for thread_id, info in partitions.items():\n",
        "    for (i, j) in info['elements']:\n",
        "        grid[i, j] = thread_id\n",
        "\n",
        "for i in range(8):\n",
        "    print(\"  \" + \" \".join(f\"{grid[i, j]}\" for j in range(8)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. FlashAttentionä¸­çš„åˆ†å—ç¤ºä¾‹\n",
        "\n",
        "è®©æˆ‘ä»¬æ¨¡æ‹ŸFlashAttentionå¦‚ä½•ä½¿ç”¨è¿™äº›æ¦‚å¿µå¤„ç†Qã€KçŸ©é˜µã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_flash_attention_tiling():\n",
        "    \"\"\"\n",
        "    æ¨¡æ‹ŸFlashAttentionçš„åˆ†å—è¿‡ç¨‹\n",
        "    \"\"\"\n",
        "    # å‚æ•°\n",
        "    seqlen = 16   # åºåˆ—é•¿åº¦ (ç®€åŒ–)\n",
        "    head_dim = 8  # å¤´ç»´åº¦ (ç®€åŒ–)\n",
        "    Br = 4        # Qçš„å—å¤§å°\n",
        "    Bc = 4        # Kçš„å—å¤§å°\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(\"FlashAttentionåˆ†å—æ¨¡æ‹Ÿ\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nå‚æ•°:\")\n",
        "    print(f\"  åºåˆ—é•¿åº¦ (N): {seqlen}\")\n",
        "    print(f\"  å¤´ç»´åº¦ (d): {head_dim}\")\n",
        "    print(f\"  Qå—å¤§å° (Br): {Br}\")\n",
        "    print(f\"  Kå—å¤§å° (Bc): {Bc}\")\n",
        "    \n",
        "    # åˆ›å»ºQå’ŒKçŸ©é˜µ\n",
        "    Q = np.random.randn(seqlen, head_dim).astype(np.float16)\n",
        "    K = np.random.randn(seqlen, head_dim).astype(np.float16)\n",
        "    \n",
        "    print(f\"\\nçŸ©é˜µå½¢çŠ¶:\")\n",
        "    print(f\"  Q: {Q.shape}\")\n",
        "    print(f\"  K: {K.shape}\")\n",
        "    \n",
        "    # è®¡ç®—å—æ•°\n",
        "    num_blocks_q = seqlen // Br\n",
        "    num_blocks_k = seqlen // Bc\n",
        "    \n",
        "    print(f\"\\nåˆ†å—ä¿¡æ¯:\")\n",
        "    print(f\"  Qæ–¹å‘å—æ•°: {num_blocks_q}\")\n",
        "    print(f\"  Kæ–¹å‘å—æ•°: {num_blocks_k}\")\n",
        "    print(f\"  æ€»è¿­ä»£æ¬¡æ•°: {num_blocks_q * num_blocks_k}\")\n",
        "    \n",
        "    # æ¨¡æ‹Ÿåˆ†å—è¿­ä»£\n",
        "    print(\"\\nåˆ†å—è¿­ä»£è¿‡ç¨‹:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for i in range(num_blocks_q):\n",
        "        # åŠ è½½Qçš„ç¬¬iå—åˆ°SRAM\n",
        "        q_start = i * Br\n",
        "        q_end = q_start + Br\n",
        "        Q_block = Q[q_start:q_end, :]  # [Br, d]\n",
        "        \n",
        "        print(f\"\\nå¤–å¾ªç¯ i={i}: Q[{q_start}:{q_end}, :]\")\n",
        "        \n",
        "        for j in range(num_blocks_k):\n",
        "            # åŠ è½½Kçš„ç¬¬jå—åˆ°SRAM\n",
        "            k_start = j * Bc\n",
        "            k_end = k_start + Bc\n",
        "            K_block = K[k_start:k_end, :]  # [Bc, d]\n",
        "            \n",
        "            # è®¡ç®—å±€éƒ¨æ³¨æ„åŠ›åˆ†æ•°\n",
        "            S_block = Q_block @ K_block.T  # [Br, Bc]\n",
        "            \n",
        "            print(f\"  å†…å¾ªç¯ j={j}: K[{k_start}:{k_end}, :] -> S[{q_start}:{q_end}, {k_start}:{k_end}]\")\n",
        "            print(f\"    S_block shape: {S_block.shape}\")\n",
        "    \n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(\"å…³é”®ä¼˜åŒ–:\")\n",
        "    print(\"1. Qå—åªåŠ è½½ä¸€æ¬¡ï¼ŒKå—åœ¨å†…å¾ªç¯ä¸­éå†\")\n",
        "    print(\"2. SçŸ©é˜µä»ä¸å®Œæ•´å­˜å‚¨ï¼Œåªæœ‰å½“å‰å—åœ¨SRAMä¸­\")\n",
        "    print(\"3. ä½¿ç”¨online softmaxå¢é‡è®¡ç®—æœ€ç»ˆç»“æœ\")\n",
        "\n",
        "simulate_flash_attention_tiling()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. cuteä»£ç ä¸Pythonå¯¹ç…§\n",
        "\n",
        "è®©æˆ‘ä»¬å¯¹æ¯”cuteçš„C++ä»£ç å’Œæˆ‘ä»¬çš„Pythonæ¨¡æ‹Ÿã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison = \"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                     cute C++ vs Python æ¨¡æ‹Ÿå¯¹ç…§                               â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  1. åˆ›å»ºLayout                                                                â•‘\n",
        "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘\n",
        "â•‘  cute C++:                                                                    â•‘\n",
        "â•‘    Layout layout = make_layout(make_shape(4, 3), make_stride(3, 1));         â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  Pythonæ¨¡æ‹Ÿ:                                                                  â•‘\n",
        "â•‘    layout = Layout((4, 3), (3, 1))                                           â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  2. åˆ›å»ºTensor                                                                â•‘\n",
        "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘\n",
        "â•‘  cute C++:                                                                    â•‘\n",
        "â•‘    Tensor mQ = make_tensor(make_gmem_ptr(ptr), layout);                      â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  Pythonæ¨¡æ‹Ÿ:                                                                  â•‘\n",
        "â•‘    tensor = Tensor(data, layout)                                             â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  3. è·å–å±€éƒ¨Tile                                                              â•‘\n",
        "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘\n",
        "â•‘  cute C++:                                                                    â•‘\n",
        "â•‘    Tensor tile = local_tile(mQ, tile_shape, tile_coord);                     â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  Pythonæ¨¡æ‹Ÿ:                                                                  â•‘\n",
        "â•‘    tile = local_tile(tensor, tile_shape, tile_coord)                         â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  4. åˆ†åŒº                                                                      â•‘\n",
        "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘\n",
        "â•‘  cute C++:                                                                    â•‘\n",
        "â•‘    auto thr_copy = tiled_copy.get_slice(thread_idx);                         â•‘\n",
        "â•‘    Tensor tQgQ = thr_copy.partition_S(gQ);                                   â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â•‘  Pythonæ¨¡æ‹Ÿ:                                                                  â•‘\n",
        "â•‘    partitions = partition_for_threads(shape, num_threads, thread_layout)     â•‘\n",
        "â•‘                                                                               â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\"\n",
        "print(comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. æ€»ç»“\n",
        "\n",
        "é€šè¿‡è¿™ä¸ªnotebookï¼Œæˆ‘ä»¬ç†è§£äº†ï¼š\n",
        "\n",
        "1. **Layout**: ç”¨Shapeå’ŒStrideæè¿°å†…å­˜å¸ƒå±€\n",
        "2. **Tensor**: æ•°æ® + Layoutçš„ç»„åˆ\n",
        "3. **local_tile**: ä»å¤§çŸ©é˜µä¸­è·å–å°å—è§†å›¾\n",
        "4. **Partition**: å°†æ•°æ®åˆ†é…ç»™å¤šä¸ªçº¿ç¨‹\n",
        "\n",
        "è¿™äº›æŠ½è±¡è®©FlashAttentionçš„å®ç°å˜å¾—æ›´åŠ æ¸…æ™°å’Œå¯ç»´æŠ¤ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š å»¶ä¼¸é˜…è¯»\n",
        "\n",
        "- [cute Layoutæ•™ç¨‹](https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md)\n",
        "- [cute Tensoræ•™ç¨‹](https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/02_tensor.md)\n",
        "- [cute MMAæ•™ç¨‹](https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/0t_mma_atom.md)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
